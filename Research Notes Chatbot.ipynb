{"cells":[{"cell_type":"markdown","id":"8c8fde4c-9222-4265-b72b-8d7693520250","metadata":{},"source":["# Using Retrieval-Augmented Generation to Search Research Notes Database"]},{"cell_type":"markdown","id":"3e302e1c-4c18-4c44-87fd-ba935c3a0853","metadata":{},"source":["Retrieval-augmented generation, or _RAG_, is a technique used with large language models to provide additional context without fine-tuning or retraining. It enhances the ability of language models to provide factual responses, which is a limitation of classical setups.\n","\n","The goal of this project is to build a question-answering bot for alternative data related questions. To achieve this, we will use RAG to provide factual information to the language model. We will upload the alternative data news to a vector database and use it to search for relevant context for the language model.\n","\n","We will be using the following tools and models:\n","- [OpenAI](https://openai.com)'s `gpt-3.5-turbo` model for prompt completions\n","- OpenAI's `text-embedding-ada-002` model to create vector embeddings\n","- [Pinecone](https://www.pinecone.io/) as the vector database to store the embeddings\n","- [langchain](https://www.langchain.com/) as the tool to interact with OpenAI and Pinecone\n","\n","The dataset used for this project is sourced from a real company news dataset. The underlying news headlines were also generated through OpenAI text completion algorithms."]},{"cell_type":"markdown","id":"8231d2c6-275e-4399-b7cd-84e112831d08","metadata":{},"source":["## Before you begin"]},{"cell_type":"markdown","id":"785d7fac-edb2-482f-be2b-c63dc2882103","metadata":{},"source":["To get started with this project, you'll need a developer account for OpenAI and Pinecone. Follow the steps in the [getting-started.ipynb](https://app.datacamp.com/workspace/w/f1d996aa-0aaa-47e3-bd61-2b5b5a0fa558/edit/getting-started.ipynb) notebook to create an API key and store it in Workspace.\n","\n","For this project, we will assume that you have already set the `OPENAI_API_KEY` and `PINECONE_API_KEY` environment variables."]},{"cell_type":"markdown","id":"a9274661-8d8c-4cc5-901e-5fc497866b89","metadata":{},"source":["## Setup"]},{"cell_type":"markdown","id":"2cf847fd-f8f8-49f6-9b43-0eb098239072","metadata":{},"source":["To perform this analysis, we need to install the following packages:\n","\n","- `openai`: for interacting with OpenAI\n","- `pinecone-client`: for interacting with Pinecone\n","- `tiktoken`: a string encoder that generates tokens used by OpenAI. It is useful for estimating the number of tokens used.\n","- `langchain`: the toolchain used to interact with OpenAI and Pinecone"]},{"cell_type":"markdown","id":"92a9caca-70fd-4ac0-aa15-1bee55c456d3","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"b1fcd794-b29c-4010-8be0-651a452b2044","metadata":{},"source":["Run the cell below to install the corresponding packages."]},{"cell_type":"code","execution_count":1,"id":"14de5322-82bf-475e-9e08-e20a5bc8b9d7","metadata":{"executionCancelledAt":null,"executionTime":8864,"lastExecutedAt":1695209311314,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%capture\n# Below we installed specific versions of the packages\n# Feel free to experiment with different versions\n# However, the workspace below is only tested with these specific versions\n!pip install pinecone-client==2.2.2 openai==0.28.0 tiktoken==0.5.1 langchain==0.0.291","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[],"source":["%%capture\n","# Below we installed specific versions of the packages\n","# Feel free to experiment with different versions\n","# However, the workspace below is only tested with these specific versions\n","!pip install pinecone-client==2.2.2 openai==0.28.0 tiktoken==0.5.1 langchain==0.0.291"]},{"cell_type":"code","execution_count":2,"id":"03110dee","metadata":{},"outputs":[{"data":{"text/plain":["'c:\\\\Users\\\\ahmed\\\\Downloads'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.getcwd()"]},{"cell_type":"code","execution_count":3,"id":"a5531d16","metadata":{},"outputs":[],"source":["# Set up secrets file\n","\n","def load_secrets(file_path):\n","    secrets = {}\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.strip() and not line.startswith('#'):  # Exclude empty and comment lines\n","                key, value = line.strip().split('=', 1)\n","                secrets[key] = value\n","    return secrets\n","\n","# Load your secrets\n","secrets_file_path = 'c:\\\\Users\\\\ahmed\\\\Downloads\\\\chatbot_secrets.env'  # Update this to your file's path\n","secrets = load_secrets(secrets_file_path)"]},{"cell_type":"markdown","id":"a214b50c-8ee1-4a1d-a940-4ea1d16da052","metadata":{},"source":["## Task 1: Import the Research Notes Data"]},{"cell_type":"code","execution_count":4,"id":"7d97255b-a124-41a3-b389-2be5b409eff0","metadata":{"executionCancelledAt":null,"executionTime":124,"lastExecutedAt":1695209311439,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import pandas as pd\nimport pandas as pd\n\n# Import IMBD.csv and transform to create the movies dataframe\nmovies = pd.read_csv(\"IMDB.csv\")\nmovies = movies.rename(columns = {\n    \"primaryTitle\": \"movie_title\",\n    \"Description\": \"movie_description\",\n})\nmovies[\"source\"] = \"https://www.imdb.com/title/\" + movies[\"tconst\"]\nmovies = movies.loc[movies[\"titleType\"] == \"movie\"]\nmovies = movies[[\"movie_title\", \"movie_description\", \"source\", \"genres\"]]\n\n# Show the head of movies\nmovies.head()","outputsMetadata":{"0":{"height":193,"type":"dataFrame"}}},"outputs":[],"source":["import pandas as pd\n","\n","research_notes = pd.read_csv(\"normalized_rn.csv\")"]},{"cell_type":"code","execution_count":5,"id":"c756883a","metadata":{},"outputs":[{"data":{"text/plain":["Index(['Unnamed: 0', 'gvkey', 'note', 'note_creation', 'data_source', 'conm'], dtype='object')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["research_notes.columns"]},{"cell_type":"code","execution_count":6,"id":"fab0bf99","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>gvkey</th>\n","      <th>note</th>\n","      <th>note_creation</th>\n","      <th>data_source</th>\n","      <th>conm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1690</td>\n","      <td>Republican House Representative Lloyd Smucker ...</td>\n","      <td>2024-01-10</td>\n","      <td>Politician trading</td>\n","      <td>APPLE INC</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2018</td>\n","      <td>On the 1st of April, BANK LEUMI LE ISRAEL B M ...</td>\n","      <td>2024-01-10</td>\n","      <td>Share buyback intention</td>\n","      <td>BANK LEUMI LE ISRAEL B M</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2176</td>\n","      <td>The Republican House representative, Morris Br...</td>\n","      <td>2024-01-10</td>\n","      <td>Politician trading</td>\n","      <td>BERKSHIRE HATHAWAY</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2435</td>\n","      <td>On the 13th of July, BROWN FORMAN CORP will la...</td>\n","      <td>2024-01-10</td>\n","      <td>Share buyback intention</td>\n","      <td>BROWN FORMAN CORP</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2968</td>\n","      <td>Democrat House Representative Bradley Schneide...</td>\n","      <td>2024-01-10</td>\n","      <td>Politician trading</td>\n","      <td>JPMORGAN CHASE &amp; CO</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  gvkey                                               note  \\\n","0           0   1690  Republican House Representative Lloyd Smucker ...   \n","1           1   2018  On the 1st of April, BANK LEUMI LE ISRAEL B M ...   \n","2           2   2176  The Republican House representative, Morris Br...   \n","3           3   2435  On the 13th of July, BROWN FORMAN CORP will la...   \n","4           4   2968  Democrat House Representative Bradley Schneide...   \n","\n","  note_creation              data_source                      conm  \n","0    2024-01-10       Politician trading                 APPLE INC  \n","1    2024-01-10  Share buyback intention  BANK LEUMI LE ISRAEL B M  \n","2    2024-01-10       Politician trading        BERKSHIRE HATHAWAY  \n","3    2024-01-10  Share buyback intention         BROWN FORMAN CORP  \n","4    2024-01-10       Politician trading       JPMORGAN CHASE & CO  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["research_notes.head()"]},{"cell_type":"markdown","id":"4b05e160-1451-4a57-bb94-533003ae18c2","metadata":{},"source":["## Task 2: Create Documents from the Data"]},{"cell_type":"markdown","id":"2b9b5682-3d6a-4954-adbd-67da3c94b6d1","metadata":{},"source":["Later in this project, we will be creating vector embeddings for all of the rows in the `research_notes` DataFrame. Before we do so, we need to create [Document](https://docs.langchain.com/docs/components/schema/document) objects from the data in the DataFrame. To accomplish this, we can utilize the `DataFrameLoader` class provided by langchain, which allows us to create documents from a pandas DataFrame.\n","\n","For the main content of the documents, we will create a summary string that includes relevant information about each research note/news headline. "]},{"cell_type":"markdown","id":"0caf40d3-d1e8-4eb6-ad48-5fa90374b750","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"ea6b483c-f719-4174-be5c-c7589d7de738","metadata":{},"source":["- Import `DataFrameLoader` from `langchain.document_loaders`\n","- Only keep the columns `page_content` and `source` in the DataFrame\n","- Use `DataFrameLoader` to load documents from the `research_notes` DataFrame into `docs`. Use `\"page_content\"` as the `page_content_column`.\n","- Print the first 3 documents and the total number of documents"]},{"cell_type":"code","execution_count":7,"id":"bca1a148-ca90-4380-8dba-b574068ed108","metadata":{"executionCancelledAt":null,"executionTime":1913,"lastExecutedAt":1695209313352,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import DataFrameLoader\nfrom langchain.document_loaders import DataFrameLoader\n\n# Create page content column\nmovies[\"page_content\"] = \"Title: \" + movies[\"movie_title\"] + \"\\n\" + \\\n                         \"Genre: \" + movies[\"genres\"] + \"\\n\" + \\\n                         \"Description: \" +movies[\"movie_description\"]\n\n# Drop all columns except for page_content and source\nmovies = movies[[\"page_content\", \"source\"]]\n\n# Load the documents from the dataframe into docs\n# The page content column is 'movie_description'\ndocs = DataFrameLoader(\n    movies,\n    page_content_column=\"page_content\",\n).load()\n\n# Print the first 3 documents and the number of documents\nprint(f\"First 3 documents: {docs[:3]}\")\nprint(f\"Number of documents: {len(docs)}\")","outputsMetadata":{"0":{"height":329,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["First 3 documents: [Document(page_content='Company: APPLE INC\\nNote: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'}), Document(page_content='Company: BANK LEUMI LE ISRAEL B M\\nNote: On the 1st of April, BANK LEUMI LE ISRAEL B M will initiate a share buyback program with the goal of repurchasing 700M (ILS) from the market.\\nSource: Share buyback intention', metadata={'data_source': 'Share buyback intention'}), Document(page_content='Company: BERKSHIRE HATHAWAY\\nNote: The Republican House representative, Morris Brooks, disclosed a purchase of BERKSHIRE HATHAWAY BRK/B with an estimated value of around 32.5K USD.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'})]\n","Number of documents: 346\n"]}],"source":["# Import DataFrameLoader\n","from langchain.document_loaders import DataFrameLoader\n","\n","# Create page content column\n","research_notes[\"page_content\"] = \"Company: \" + research_notes[\"conm\"] + \"\\n\" + \\\n","                         \"Note: \" + research_notes[\"note\"] + \"\\n\" + \\\n","                         \"Source: \" + research_notes[\"data_source\"]\n","\n","# Drop all columns except for page_content and source\n","research_notes = research_notes[[\"page_content\", \"data_source\"]]\n","\n","# Load the documents from the dataframe into docs\n","docs = DataFrameLoader(\n","    research_notes,\n","    page_content_column=\"page_content\",\n",").load()\n","\n","# Print the first 3 documents and the number of documents\n","print(f\"First 3 documents: {docs[:3]}\")\n","print(f\"Number of documents: {len(docs)}\")"]},{"cell_type":"markdown","id":"0b05e466-807c-42a2-8272-46ba547ae7b6","metadata":{},"source":["## Task 3: Estimate the Cost of Embedding"]},{"cell_type":"markdown","id":"a8f9087b-d05a-4e4a-a7e7-0e3b13ce8b5d","metadata":{},"source":["We're going to be using OpenAI to calculate [vector embeddings](https://platform.openai.com/docs/guides/embeddings/embeddings) of the document texts. Creating embeddings is a form of dimensionality reduction, where we assign the text to a point in an N-dimensional space. Texts that are semantically close to each other should end up being close to each other in the N-dimensional space.\n","\n","Luckily, OpenAI has several models that are trained to calculate these kinds of embeddings, so we don't have to do that ourselves. Of course, a cost is associated with this. You can derive the cost from the [pricing page of OpenAI](https://openai.com/pricing).\n","\n","The calculation is based on the amount of _tokens_ in the text. All text is encoded into tokens to be used by OpenAI. On average, a token consists of roughly 3 characters. However, we can calculate the exact tokens for a string of text by using the `tiktoken` package.\n","\n","The goal of this task is to calculate the number of tokens in the documents, to then extrapolate the estimated cost."]},{"cell_type":"markdown","id":"1d29906f-89e9-499e-846b-b69b94920413","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"f4b64d17-7f48-4fe0-90f4-47b70a39e1d4","metadata":{},"source":["- Import `tiktoken`\n","- Create the encoder, use the `\"cl100k_base\"` encoder. This is the encoder used by OpenAI to calculate the embeddings for text using the `text-embedding-ada-002` model.\n","- Create a list that contains the amount of tokens for each document\n","- Calculate the estimated cost: the sum of all tokens, divided by 1000 tokens, multiplied with $0.0001"]},{"cell_type":"code","execution_count":8,"id":"44a1bbe0-b0c5-4295-be95-92711e751755","metadata":{"executionCancelledAt":null,"executionTime":1108,"lastExecutedAt":1695209314460,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import tiktoken\nimport tiktoken\n\n# Create the encoder\nencoder = tiktoken.get_encoding(\"cl100k_base\")\n\n# Create a list containing the number of tokens for each document\ntokens_per_doc = [len(encoder.encode(doc.page_content)) for doc in docs]\n\n# Show the estimated cost, which is the sum of the amount of tokens divided by 1000, times $0.0001\ntotal_tokens = sum(tokens_per_doc)\ncost_per_1000_tokens = 0.0001\ncost =  (total_tokens / 1000) * cost_per_1000_tokens\ncost"},"outputs":[{"data":{"text/plain":["0.0022922999999999997"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Import tiktoken\n","import tiktoken\n","\n","# Create the encoder\n","encoder = tiktoken.get_encoding(\"cl100k_base\")\n","\n","# Create a list containing the number of tokens for each document\n","tokens_per_doc = [len(encoder.encode(doc.page_content)) for doc in docs]\n","\n","# Show the estimated cost, which is the sum of the amount of tokens divided by 1000, times $0.0001\n","total_tokens = sum(tokens_per_doc)\n","cost_per_1000_tokens = 0.0001\n","cost =  (total_tokens / 1000) * cost_per_1000_tokens\n","cost"]},{"cell_type":"markdown","id":"44c07a82-540e-4c7c-ac04-9426b8511933","metadata":{},"source":["## Task 4: Create the Index on Pinecone"]},{"cell_type":"markdown","id":"a9084628-ad8d-488f-85b5-230ca5130e3e","metadata":{},"source":["Looks like calculating the embeddings is not going to be too expensive. It's always smart to get a rough estimate on the amount of tokens used, so you get an idea of the cost of calculating the embeddings using OpenAI.\n","\n","Now we're ready to create the index on Pinecone. An [index in Pinecone](https://docs.pinecone.io/docs/indexes) can be used to store vectors. You can compare an index in Pinecone to a table in SQL, it stores information of one type of object.\n","\n","In a later task, we'll be creating vectors from the documents we just created using OpenAI's second-generation embedding model. It's important to already know the embeddings we're going to use since we need to know the output dimensions to create an index. For `text-embedding-ada-002`, this is `1536` dimensions ([source](https://platform.openai.com/docs/guides/embeddings/second-generation-models)).\n","\n","At the end of this task, you should be able to find your new index in the [Pinecone UI](https://app.pinecone.io/).\n","\n","![Pinecone UI](pinecone_ui.png)"]},{"cell_type":"markdown","id":"498035c1-ce3e-4634-8d98-084650953dc3","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"df296f65-441a-4b72-8ca0-80d878aa8db2","metadata":{},"source":["- Import `os` and `pinecone`\n","- Use `.init` to initialize the Pinecone client with the `\"PINECONE_API_KEY\"` environment variable. Use the `\"gcp-starter\"` environment on Pinecone.\n","- Print all the indexes on Pinecone by using `.list_indexes` on the client.\n","- Use `.create_index` to create an index, but only if it does not exist yet. The metric we'll use is the `\"cosine\"` distance, and as we mentioned above, the embeddings wil have `1536` dimensions."]},{"cell_type":"code","execution_count":28,"id":"b8841311-9c1b-4b5c-a7f1-6926128de7e4","metadata":{"executionCancelledAt":null,"executionTime":16120,"lastExecutedAt":1695209330580,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import os and pinecone\nimport os\nimport pinecone\n\n# Initialize pinecone using the `PINECONE_API_KEY` variable. Use the gcp-starter environment\npinecone.init(\n    api_key=os.getenv(\"PINECONE_API_KEY\"),\n    environment=\"gcp-starter\"\n)\n\n# Print the indexes\nprint(pinecone.list_indexes())\n\nindex_name = \"imdb-movies\"\n\n# First check that the given index does not exist yet\nif index_name not in pinecone.list_indexes():\n    # Create the 'imbd-movies' index if it does not exist\n    pinecone.create_index(\n        name=index_name,\n        metric='cosine',\n        dimension=1536,\n    )","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]}],"source":["# Import os and pinecone\n","import os\n","import pinecone\n","\n","# Initialize pinecone using the `PINECONE_API_KEY` variable. Use the gcp-starter environment\n","pinecone.init(\n","    api_key=secrets[\"PINECONE_API_KEY\"],\n","    environment=\"gcp-starter\"\n",")\n","\n","# Print the indexes\n","print(pinecone.list_indexes())\n","\n","index_name = \"research-notes-test\"\n","\n","# First check that the given index does not exist yet\n","if index_name not in pinecone.list_indexes():\n","    # Create the index if it does not exist\n","    pinecone.create_index(\n","        name=index_name,\n","        metric='cosine',\n","        dimension=1536,\n","    )"]},{"cell_type":"markdown","id":"447ca370-700a-4fa9-bb85-2ebc49a89308","metadata":{},"source":["## Task 5: Fill the Index with the Documents"]},{"cell_type":"markdown","id":"9ea4d375-28be-4deb-a11d-960215c13589","metadata":{},"source":["Now that we have the vector index at our disposal, it's time to populate it with some vectors. In this task, we'll need to:\n","\n","1. Generate vector embeddings for all documents in `docs`. We'll utilize OpenAI for this purpose. langchain provides a convenient helper for this task, `langchain.embeddings.openai.OpenAIEmbeddings`, which you can use to generate embeddings using the latest `text-embedding-ada-002` model.\n","2. Populate the vector index in Pinecone with these embeddings. Fortunately, langchain also offers assistance with this through the [`langchain.vectorstores.Pinecone`](https://python.langchain.com/docs/integrations/vectorstores/pinecone) helper.\n","\n","These two steps can be combined using the convenient helper method `.from_document` of the `Pinecone` class. This method accepts an embedding model as input and efficiently calculates the embeddings, subsequently uploading them to Pinecone. We will also introduce some control flow to the code to ensure we do not add data to the Pinecone index if it already contains data. To achieve this, we can make use of the `.from_existing_index` method of `Pinecone`.\n","\n","In addition to storing vectors, Pinecone allows the storage of additional metadata. When using the langchain helpers, it automatically assumes that vectors should be created from the `page_content` property of each `Document`. All other properties will be included as metadata.\n","\n","You can verify that everything has worked correctly by accessing the index in the Pinecone UI."]},{"cell_type":"markdown","id":"290c64c4-c5d2-426f-bb71-2d98fdd2d89c","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"1e1cc456-8a07-4775-892c-729f4b048a86","metadata":{},"source":["- Import `OpenAIEmbeddings` from `langchain.embeddings.openai` and `Pinecone` from `langchain.vectorstores` and `Index` from `pinecone.index`\n","- Create the `embeddings` object, which should be an instance of `OpenAIEmbeddings`. The defaults are good to go here.\n","- Use `Pinecone.from_documents` to fill up the vector index on Pinecone using the given documents and embeddings object. This will take a while to run, as it will automatically calculate embeddings from all of the `page_content` properties of the documents, and upload that along with metadata to Pinecone. Assign the result to `docsearch`.\n","   - Some control flow code is already provided for you, this will make sure you use the existing index if it already contains some vectors and avoids filling it up twice.\n","- Test out the `docsearch` vector database object, by calling `.as_retriever().get_relevant_documents` with a given question. This will first create a [retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/) from the vector database, and then use that to match the most similar documents in the database."]},{"cell_type":"code","execution_count":44,"id":"2540833a-e503-4717-9dd6-0f90e2c10986","metadata":{"executionCancelledAt":null,"executionTime":32053,"lastExecutedAt":1695209362634,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import OpenAIEmbeddings, Pinecone and Index\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Pinecone\nfrom pinecone.index import Index\n\n# Create the embeddings object\nembeddings = OpenAIEmbeddings()\n\nindex = Index(index_name)\n\n# Check if there is already some data in the index on Pinecone\nif index.describe_index_stats()['total_vector_count'] > 0:\n    # If there is, use from_existing_index to use the vector store\n    docsearch = Pinecone.from_existing_index(index_name, embeddings)\nelse:\n    # If there is not, use from_documents to fill the vector store\n    docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n\nquestion = \"What's a good movie about an epic viking?\"\n    \n# Use the vector database as a retriever and get the relevant documents for a quesiton\ndocsearch.as_retriever().get_relevant_documents(question)"},"outputs":[{"data":{"text/plain":["[Document(page_content='Company: APPLE INC\\nNote: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'}),\n"," Document(page_content='Company: APPLE INC\\nNote: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'}),\n"," Document(page_content='Company: ALPHABET INC\\nNote: John Curtis, a member of the Republican House, recently announced the sale of ALPHABET INC GOOGL stocks for approximately 32.5K USD at a press conference.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'}),\n"," Document(page_content='Company: ALPHABET INC\\nNote: John Curtis, a member of the Republican House, recently announced the sale of ALPHABET INC GOOGL stocks for approximately 32.5K USD at a press conference.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'})]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["# Import OpenAIEmbeddings, Pinecone and Index\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.vectorstores import Pinecone\n","from pinecone.index import Index\n","\n","# Create the embeddings object\n","embeddings = OpenAIEmbeddings(openai_api_key=secrets[\"OPENAI_API_KEY\"])\n","\n","index = Index(index_name)\n","\n","# Check if there is already some data in the index on Pinecone\n","if index.describe_index_stats()['total_vector_count'] > 0:\n","    # If there is, use from_existing_index to use the vector store\n","    docsearch = Pinecone.from_existing_index(index_name, embeddings)\n","else:\n","    # If there is not, use from_documents to fill the vector store\n","    docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n","\n","question = \"What has been happening with apple inc?\"\n","    \n","# Use the vector database as a retriever and get the relevant documents for a quesiton\n","docsearch.as_retriever().get_relevant_documents(question)"]},{"cell_type":"code","execution_count":56,"id":"116f1dee","metadata":{},"outputs":[{"data":{"text/plain":["Document(page_content='Company: SLACK TECHNOLOGIES INC\\nNote: House Democrat Nancy Pelosi has announced a purchase of SLACK TECHNOLOGIES INC WORK, which is estimated to be worth around 274.9K US dollars.\\nSource: Politician trading', metadata={'data_source': 'Politician trading'})"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["question = \"What is the politician trading activity in Apple?\"\n","docsearch.as_retriever().get_relevant_documents(question)[3]"]},{"cell_type":"markdown","id":"9de4edfc-55fa-42ec-a23d-3d9607216e2e","metadata":{},"source":["## Task 6: Create Prompts for RAG"]},{"cell_type":"markdown","id":"66aa737c-4947-48d4-a9e9-4d5cd38b21c0","metadata":{},"source":["\n","We require two types of [prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/):\n","- A template that demonstrates how the information in relevant documents is presented to the LLM\n","- A template that combines the context with the rest of the prompt\n","\n","Some example prompt templates are provided in the sample code below, which you are free to edit. Notice that these example templates contain `=========` separators between different parts of the text. These kinds of delimiters are a common tactic to help the LLM distinguish between different parts of your input prompt."]},{"cell_type":"markdown","id":"04e31746-7fd7-4a2c-a658-d1640716e930","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"b73889c7-4776-4290-abe1-9bb272665c79","metadata":{},"source":["- Import `PromptTemplate` from `langchain.prompts`\n","- Some example prompt templates are already provided for you. You are free to adapt them at your will. There are two prompt templates:\n","  - `DOCUMENT_PROMPT`: this template shows how a summary text is created for each document. The properties between the curly brackets (`{`) are replaced with the properties of each `Document`.\n","  - `QUESTION_PROMPT`: this template creates the full prompt that is sent to the LLM. `question` is replaced by the question asked by the user, and `summaries` is replaced with the summary of each relevant document, created by the `DOCUMENT_PROMPT` template\n","- Create the `PromptTemplate` objects by using `PromptTemplate.from_template`. Call them `document_prompt` and `question_prompt`, respectively."]},{"cell_type":"code","execution_count":54,"id":"45d251c9","metadata":{},"outputs":[{"data":{"text/plain":["'Company: APPLE INC\\nNote: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD.\\nSource: Politician trading'"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["research_notes.iloc[0][\"page_content\"]"]},{"cell_type":"code","execution_count":69,"id":"9b2932a2-8b1b-48d6-a18d-bc2f12ebc2c5","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1695209362686,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import PromptTemplate\nfrom langchain.prompts import PromptTemplate\n\n# Read/adapt the prompts below at will\nDOCUMENT_PROMPT = \"\"\"{page_content}\nIMDB link: {source}\n=========\"\"\"\n\nQUESTION_PROMPT = \"\"\"Given the following extracted parts of a movie database and a question, create a final answer with the IMDB link as source (\"SOURCE\").\nIf you don't know the answer, just say that you don't know. Don't try to make up an answer.\nALWAYS return a \"SOURCE\" part in your answer.\n\nQUESTION: What's a good movie about a robot to watch with my kid?\n=========\nTitle: A.I. Artificial Intelligence\nGenre: Drama,Sci-Fi\nDescription: A robotic boy, the first programmed to love, David (Haley Joel Osment) is adopted as a test case by a Cybertronics employee (Sam Robards) and his wife (Frances O'Connor). Though he gradually becomes their child, a series of unexpected circumstances make this life impossible for David. Without final acceptance by humans or machines, David embarks on a journey to discover where he truly belongs, uncovering a world in which the line between robot and machine is both vast and profoundly thin.\nIMDB link: https://www.imdb.com/title/tt0212720\n=========\nTitle: I, Robot\nGenre: Action,Mystery,Sci-Fi\nDescription: In 2035, highly intelligent robots fill public service positions throughout the world, operating under three rules to keep humans safe. Despite his dark history with robotics, Detective Del Spooner (Will Smith) investigates the alleged suicide of U.S. Robotics founder Alfred Lanning (James Cromwell) and believes that a human-like robot (Alan Tudyk) murdered him. With the help of a robot expert (Bridget Moynahan), Spooner discovers a conspiracy that may enslave the human race.\nIMDB link: https://www.imdb.com/title/tt0343818\n=========\nTitle: The Iron Giant\nGenre: Action,Adventure,Animation\nDescription: In this animated adaptation of Ted Hughes' Cold War fable, a giant alien robot (Vin Diesel) crash-lands near the small town of Rockwell, Maine, in 1957. Exploring the area, a local 9-year-old boy, Hogarth, discovers the robot, and soon forms an unlikely friendship with him. When a paranoid government agent, Kent Mansley, becomes determined to destroy the robot, Hogarth and beatnik Dean McCoppin (Harry Connick Jr.) must do what they can to save the misunderstood machine.\nIMDB link: https://www.imdb.com/title/tt0129167\n=========\nFINAL ANSWER: 'The Iron Giant' is an animated movie about a friendship between a robot and a kid. It would be a good movie to watch with a kid.\nSOURCE: https://www.imdb.com/title/tt0129167\n\nQUESTION: {question}\n=========\n{summaries}\nFINAL ANSWER:\"\"\"\n\n# Create prompt template objects\ndocument_prompt = PromptTemplate.from_template(DOCUMENT_PROMPT)\nquestion_prompt = PromptTemplate.from_template(QUESTION_PROMPT)"},"outputs":[],"source":["# Import PromptTemplate\n","from langchain.prompts import PromptTemplate\n","\n","# Read/adapt the prompts below at will\n","DOCUMENT_PROMPT = \"\"\"{page_content}\n","=========\"\"\"\n","\n","QUESTION_PROMPT = \"\"\"Given the following extracted parts of a a database and a question, create a final answer with the research note.\n","If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n","Be concise and do not add additional text that does not exist in the note.\n","\n","QUESTION: What is the politician trading activity in a given company?\n","=========\n","Company: APPLE INC\n","Note: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD\n","=========\n","Company: SLACK TECHNOLOGIES INC\n","Note: House Democrat Nancy Pelosi has announced a purchase of SLACK TECHNOLOGIES INC WORK, which is estimated to be worth around 274.9K US dollars\n","=========\n","FINAL ANSWER: Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD\n","\n","QUESTION: {question}\n","=========\n","{summaries}\n","FINAL ANSWER:\"\"\"\n","\n","# Create prompt template objects\n","document_prompt = PromptTemplate.from_template(DOCUMENT_PROMPT)\n","question_prompt = PromptTemplate.from_template(QUESTION_PROMPT)"]},{"cell_type":"markdown","id":"09f5e246-7f71-4d1e-ac5a-c555e37f8849","metadata":{},"source":["## Task 7: Chain Everything Together to Perform RAG"]},{"cell_type":"markdown","id":"1975eeaf-23d0-4d71-a525-01ab10b64096","metadata":{},"source":["Finally, we have the vector index filled up with information, we have the prompt templates set up. That means we have everything we need to build a question-answering bot, which can use the information retrieved from Pinecone to answer questions about the news headlines.\n","\n","We'll use the `gpt-3.5-turbo` model of OpenAI in order to provide a completion for the question prompt above.\n","\n","Langchain provides a convenient concept, called [chains](https://python.langchain.com/docs/modules/chains/), that does some of the heavy lifting when you need to combine multiple AI systems into a single application. For the purpose of this project, we'll be using the `RetrievalQAWithSourcesChain` class. This chain will accept a `question` and a `retriever`. When asked a question, it will first use the retriever to retrieve relevant documents. Afterwards, it will combine the documents into a prompt and send it to the LLM to provide a completion."]},{"cell_type":"markdown","id":"9006ac2b-f0a2-4d0a-bd50-133a39f58d54","metadata":{},"source":["### Instructions"]},{"cell_type":"markdown","id":"648165d9-66a0-4aa6-aae2-57f0136d89ad","metadata":{},"source":["- Import `RetrievalQAWithSourcesChain` from `langchain.chains` and `ChatOpenAI` from `langchain.chat_models`\n","- Use `RetrievalQAWithSourcesChain` to create the chain to answer questions. Use the `.from_chain_type` method:\n","  - Set `chain_type` set to `\"stuff\"`. This is the simplest type of chain, and will just stuff the document context in one prompt.\n","  - Set `llm` to an instance of `ChatOpenAI` with `model_name` set to `\"gpt-3.5-turbo\"` and `temperature` set to `0`.\n","  - Use the `PromptTemplate` objects you created above to pass to `chain_type_kwargs`\n","  - As a retriever, use the `docsearch.as_retriever` method you've seen before"]},{"cell_type":"code","execution_count":62,"id":"ebec430a","metadata":{},"outputs":[],"source":["question = \"What is the politician trading activity in Apple?\""]},{"cell_type":"code","execution_count":72,"id":"c5382d5f-6813-41d3-9f55-7e404c050c76","metadata":{"executionCancelledAt":null,"executionTime":2750,"lastExecutedAt":1695209365436,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import RetrievalQAWithSourcesChain and ChatOpenAI\nfrom langchain.chains import RetrievalQAWithSourcesChain\nfrom langchain.chat_models import ChatOpenAI\n\n# Create the QA bot LLM chain\nqa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n    chain_type=\"stuff\",\n    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n    chain_type_kwargs={\n        \"document_prompt\": document_prompt,\n        \"prompt\": question_prompt,\n    },\n    retriever=docsearch.as_retriever(),\n)\n\n# Ask the LLM a question about movies\nqa_with_sources(question)","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[],"source":["# Import RetrievalQAWithSourcesChain and ChatOpenAI\n","from langchain.chains import RetrievalQAWithSourcesChain\n","from langchain.chat_models import ChatOpenAI\n","\n","# Create the QA bot LLM chain\n","qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(\n","    chain_type=\"stuff\",\n","    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=secrets[\"OPENAI_API_KEY\"]),\n","    chain_type_kwargs={\n","        \"document_prompt\": document_prompt,\n","        \"prompt\": question_prompt,\n","    },\n","    retriever=docsearch.as_retriever(),\n",")\n"]},{"cell_type":"code","execution_count":73,"id":"46242764","metadata":{},"outputs":[{"data":{"text/plain":["{'question': 'What is the recent buyback activity?',\n"," 'answer': 'On the 1st of July, BANK OF AMERICA CORP will commence a share buyback program, purchasing 20.6 billion USD from the market. Citigroup Inc. will also begin a share buyback program on the same date, aiming to retrieve 17.6 billion US dollars from the market.',\n"," 'sources': ''}"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["question = \"What is the recent buyback activity?\"\n","qa_with_sources(question)"]},{"cell_type":"code","execution_count":74,"id":"e1650cf1","metadata":{},"outputs":[{"data":{"text/plain":["{'question': 'Any political trading activity in Apple?',\n"," 'answer': 'Republican House Representative Lloyd Smucker announced that he had sold shares in APPLE INC (AAPL) for approximately 32.5K USD. There is no other political trading activity in Apple.',\n"," 'sources': ''}"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["question = \"Any political trading activity in Apple?\"\n","qa_with_sources(question)"]},{"cell_type":"code","execution_count":79,"id":"701418c1","metadata":{},"outputs":[{"data":{"text/plain":["{'question': 'Any interesting insider activity related to Century Casinos?',\n"," 'answer': 'President/CEO, Peter Hoetzinger, from CENTURY CASINOS INC, reported a Buy of 100K shares worth 414.8K USD.',\n"," 'sources': ''}"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["question = \"Any interesting insider activity related to Century Casinos?\"\n","qa_with_sources(question)"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":5}
